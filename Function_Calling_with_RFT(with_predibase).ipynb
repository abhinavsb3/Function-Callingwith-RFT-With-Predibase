{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6pH4ymqCAdAGYON4NOO6T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinavsb3/Function-Callingwith-RFT-With-Predibase/blob/main/Function_Calling_with_RFT(with_predibase).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9DFpnMuD5m5"
      },
      "outputs": [],
      "source": [
        "!pip uninstall numpy -y --quiet\n",
        "!pip install predibase --quiet\n",
        "!pip install datasets --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from predibase import Predibase\n",
        "from google.colab import userdata\n",
        "from predibase import GRPOConfig, RewardFunctionsConfig, SamplingParamsConfig\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"predibase/glaive_function_calling\")\n",
        "train_df = pd.DataFrame(dataset[\"train\"])\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "gbGjEUMn1pVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt Examples\")\n",
        "print(train_df['prompt'][2])\n",
        "print(\"\\n\\nSAMPLE TOOL CALLING\")\n",
        "print(train_df['tool_call'][2])"
      ],
      "metadata": {
        "id": "8Rd2MLSSEPMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_json('./glaive_function_calling.jsonl', lines=True, orient='records')"
      ],
      "metadata": {
        "id": "jNwr8X_YEPPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tool use Reawrd function\n",
        "def global_tool_use_reward_func(prompt: str, completion: str, example: dict):\n",
        "    \"\"\"Check that the correct tools are being called, max score is 1.0.\"\"\"\n",
        "    import re\n",
        "    import ast\n",
        "    import json\n",
        "\n",
        "    rscale = 1.0\n",
        "    reward = 0.0\n",
        "\n",
        "    true_tool_call = ast.literal_eval(example['tool_call'])\n",
        "\n",
        "    try:\n",
        "        pred_tool_call = re.search(r'<tool>(.*?)</tool>', completion, re.DOTALL).group(1).strip()\n",
        "        pred_tool_call = ast.literal_eval(pred_tool_call)\n",
        "        if pred_tool_call != '':\n",
        "            assert isinstance(pred_tool_call, dict)\n",
        "            assert 'name' in pred_tool_call\n",
        "            assert 'arguments' in pred_tool_call\n",
        "    except Exception as e:\n",
        "        print(f'Error parsing tool call: {e} for {completion}')\n",
        "        return reward * rscale\n",
        "\n",
        "    if pred_tool_call == '':\n",
        "        pred_tool_call = None\n",
        "\n",
        "    # If both don't use a tool then we give full credit\n",
        "    if true_tool_call is None and pred_tool_call is None:\n",
        "        reward += 1.0\n",
        "        print(f'(CORRECT - NO TOOL). global tool use reward: {reward}')\n",
        "        return reward * rscale\n",
        "\n",
        "    # If both use a tool\n",
        "    if true_tool_call is not None and pred_tool_call is not None:\n",
        "        # For using a tool when true_tool_call is not None\n",
        "        reward += 0.1\n",
        "\n",
        "        # Why is this necessary and only happens for true_tool_call? Some issue with data upload and reload vs in completion, ast literal eval is enough.\n",
        "        if isinstance(true_tool_call['arguments'], str):\n",
        "            true_tool_call['arguments'] = json.loads(true_tool_call['arguments'])\n",
        "\n",
        "        # Name match\n",
        "        if true_tool_call['name'] != pred_tool_call['name']:\n",
        "            print(f'(PARTIAL - NAME) {true_tool_call=}, {pred_tool_call=} did not match. global tool use reward: {reward}')\n",
        "            return reward * rscale\n",
        "        reward += 0.4\n",
        "\n",
        "        # Arguments match\n",
        "        if true_tool_call['arguments'] != pred_tool_call['arguments']:\n",
        "            print(f'(PARTIAL - ARGUMENTS) {true_tool_call=}, {pred_tool_call=} did not match. global tool use reward: {reward}')\n",
        "            return reward * rscale\n",
        "\n",
        "        reward += 0.5\n",
        "        print(f'(CORRECT) {true_tool_call=}, {pred_tool_call=} global tool use reward: {reward}')\n",
        "        return reward * rscale\n",
        "    else:\n",
        "        print(f'(INCORRECT - TYPE) {true_tool_call=}, {pred_tool_call=} did not match. global tool use reward: {reward}')\n",
        "        return reward * rscale"
      ],
      "metadata": {
        "id": "1cHuZ7q3EPRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Format Reward function\n",
        "def global_format_reward_func(prompt: str, completion: str, example: dict):\n",
        "    \"\"\"Check that the generated text is in the requested format, max score is 1.0.\"\"\"\n",
        "    import re\n",
        "    import ast\n",
        "\n",
        "    reward = 0.0\n",
        "    rscale = 0.5\n",
        "\n",
        "    completion = f'<think>{completion}'\n",
        "\n",
        "    # Find <think> and </think> tags\n",
        "    think_start = completion.find('<think>')\n",
        "    think_end = completion.find('</think>')\n",
        "\n",
        "    # Find <functioncall> or <no_functioncall> tags\n",
        "    tool_start = completion.find('<tool>')\n",
        "    tool_end = completion.find('</tool>')\n",
        "\n",
        "    if think_start == -1 or think_end == -1:\n",
        "        print(f'(PARTIAL - FORMAT) missing think or tool tags. format reward: {reward}')\n",
        "        return reward * rscale\n",
        "\n",
        "    reward += 0.1\n",
        "\n",
        "    if not (think_start < think_end < tool_start < tool_end):\n",
        "        print(f'(PARTIAL - FORMAT) tags present but not in the correct order. format reward: {reward}')\n",
        "        return reward * rscale\n",
        "\n",
        "    reward += 0.1\n",
        "\n",
        "    # Check if there are any stray tags\n",
        "    think_tags = re.findall(r'</?think>', completion)\n",
        "    tool_tags = re.findall(r'</?tool>', completion)\n",
        "\n",
        "    if len(think_tags) != 2 or len(tool_tags) != 2:\n",
        "        print(f'(PARTIAL - FORMAT) found stray think or tool tags. format reward: {reward}')\n",
        "        return reward * rscale\n",
        "\n",
        "    reward += 0.2\n",
        "\n",
        "    # Check if tool call syntax is valid.\n",
        "    try:\n",
        "        pred_tool_call = re.search(r'<tool>(.*?)</tool>', completion, re.DOTALL).group(1).strip()\n",
        "        pred_tool_call = ast.literal_eval(pred_tool_call)\n",
        "        if pred_tool_call != '':\n",
        "            assert isinstance(pred_tool_call, dict)\n",
        "            assert 'name' in pred_tool_call\n",
        "            assert 'arguments' in pred_tool_call\n",
        "    except Exception as e:\n",
        "        print(f'(PARTIAL - FORMAT) could not parse result. Exception: {e} for {pred_tool_call=}. format reward: {reward}')\n",
        "        return reward * rscale\n",
        "\n",
        "    reward += 0.6\n",
        "\n",
        "    return reward * rscale"
      ],
      "metadata": {
        "id": "pg7ucIEkEPTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Length Reward function\n",
        "def global_length_reward_func(prompt: str, completion: str, example: dict):\n",
        "    \"\"\"Set a hard limit on the completion length, max score is 1.0\"\"\"\n",
        "    import math\n",
        "    norm_length_char = 2000 # 500 tokens * 4 characters per token\n",
        "    num_chars = len(completion)\n",
        "    return 1.0 if num_chars <= norm_length_char else 0.0"
      ],
      "metadata": {
        "id": "98lLqnmVEPV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the Predibase Client and Upload Your Data\n",
        "pb = Predibase(api_token=userdata.get(\"PREDIBASE_API_TOKEN\"))\n",
        "try:\n",
        "  dataset = pb.datasets.from_file(\"./glaive_function_calling.jsonl\", name=\"glaive_function_calling\")\n",
        "except:\n",
        "  dataset = pb.datasets.get(\"glaive_function_calling\")"
      ],
      "metadata": {
        "id": "JT8_hws0EPYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train with RFT!\n",
        "repo = pb.repos.create(name=\"function-calling-rft\", description=\"Train a function calling model with RFT!\", exists_ok=True)"
      ],
      "metadata": {
        "id": "7V6mHN3mEPb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adapter = pb.finetuning.jobs.create(\n",
        "    config=GRPOConfig(\n",
        "        base_model=\"qwen2-5-7b-instruct\",\n",
        "        num_generations=16,\n",
        "        sampling_params=SamplingParamsConfig(\n",
        "            max_tokens=1024\n",
        "        ),\n",
        "        reward_fns=RewardFunctionsConfig(\n",
        "            functions={\n",
        "                \"correctness\": global_tool_use_reward_func,\n",
        "                \"format\": global_format_reward_func,\n",
        "                \"length\": global_length_reward_func\n",
        "            },\n",
        "        ),\n",
        "    ),\n",
        "    dataset=dataset,\n",
        "    repo=repo,\n",
        "    description=\"Function calling model\",\n",
        ")"
      ],
      "metadata": {
        "id": "P2jXFp4YEPeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Update the Reward Functions\n",
        "def global_length_reward_func_v2(prompt: str, completion: str, example: dict):\n",
        "    \"\"\"Minimize completion length, max score is 1.0\"\"\"\n",
        "    import math\n",
        "    rscale = 0.5\n",
        "    norm_length_char = 2000 # 500 tokens * 4 characters per token\n",
        "    num_chars = len(completion)\n",
        "\n",
        "    def tanh(x):\n",
        "        return (math.exp(x) - math.exp(-x)) / (math.exp(x) + math.exp(-x))\n",
        "\n",
        "    reward =  1 - tanh(num_chars / norm_length_char)\n",
        "\n",
        "    return reward * rscale"
      ],
      "metadata": {
        "id": "W20d258uEPgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adapter_path = \"function-calling-rft/1\"\n",
        "\n",
        "# Get the original config and update it with the new reward function\n",
        "cfg = pb.adapters.get_config(adapter_path)\n",
        "cfg.reward_fns[\"length\"] = global_length_reward_func_v2\n",
        "pb.adapters.update_config(adapter_path, cfg)"
      ],
      "metadata": {
        "id": "alpc9cgAEPif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ClbjKbjpEPkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9HzDUu7BEPoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xnoTZoQlEPrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XbWA67VIEPtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KGrEFeb5EPvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nbL07rW2EPxq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}